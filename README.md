## Multimodal Machine Learning: Advances and Applications

Advanced machine learning techniques, such as deep neural networks (DNN), have achieved significant success in machine learning for single modalities (e.g., text, images or audio). However, human’s perceptual systems including visual, auditory, olfactory, and other somatosensory systems usually work together in human’s cognitive and interaction. Human’s brain, as a multimodal perceptron, can process multiple modalities simultaneously and exploit the internal correlations of the multimodal signals. For example, human’s emotion in a conversation can be understood better if both the human’s voice and behaviors are presented. To mimic the way the human brain works, there is growing interests in combining the multimodal signals as the input to the machine learning engines. However, traditional uniform machine learning models cannot handle the heterogeneity of the multimodal signal well. Multimodal machine learning is therefore a vibrant multidisciplinary field of increasing importance and with extraordinary potential.

MMSP is one of the flagship conferences focusing on the multimedia signal processing. As the most prevalent multimodal signal format, how to process the multimedia signals by the multimodal machine learning model is highly desired by the applications, such as augmented reality, affective computing, scene understanding. Multimodal machine learning would
therefore be one of the most relevant and interesting topics for the MMSP conference.

You can use the [editor on GitHub](https://github.com/wangqifei/MMSP2018_MMML/edit/master/README.md) to maintain and preview the content for your website in Markdown files.

Whenever you commit to this repository, GitHub Pages will run [Jekyll](https://jekyllrb.com/) to rebuild the pages in your site, from the content in your Markdown files.

### Areas of Interests
Possible topics include but not limited to
```markdown
1. multimodal data representations
2. multimodal feature fusion and collaborative learning
3. multi-instance machine learning
4. image/video content understanding with multimodal signal
5. natural language processing with multimodal signal
6. applications of multimodal machine learning for augmented/virtual reality
7. on-device applications with multimodal machine learning
```

### Organizers
```markdown
- Huisheng Wang
- Qifei Wang
- Bin Shen
```

### Call for papers

[PDF](https://github.com/wangqifei/MMSP2018_MMML/edit/master/README.md)

```markdown
Syntax highlighted code block

# Header 1
## Header 2
### Header 3

- Bulleted
- List

1. Numbered
2. List

**Bold** and _Italic_ and `Code` text

[Link](url) and ![Image](src)
```

For more details see [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/).

### Jekyll Themes

Your Pages site will use the layout and styles from the Jekyll theme you have selected in your [repository settings](https://github.com/wangqifei/MMSP2018_MMML/settings). The name of this theme is saved in the Jekyll `_config.yml` configuration file.

### Support or Contact

Having trouble with Pages? Check out our [documentation](https://help.github.com/categories/github-pages-basics/) or [contact support](https://github.com/contact) and we’ll help you sort it out.
